{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Pipeline 2: SNP processing with random sampling of the alternative allele__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Requirements__\n",
    "- a python environment (installed with conda for example);\n",
    "- .TSV files from the obtained with pipeline 1;\n",
    "- python `subprocess`;\n",
    "- python `Numpy`;\n",
    "- python `Pandas`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from snp_utils import ramdomly_sample_haplotypes, filter_short_introns_from_bed, filter_snps_by_interval, check_snp_codon_length\n",
    "from sfs_utils import create_unfolded_sfs_from_df, fold_sfs\n",
    "from mutational_context_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Import the tables into Pandas__\n",
    "\n",
    "We are going to use pandas to import the SNP table. Pandas is a great (if used with caution) Python package built on Numpy which allows easy dataFrame manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/WorkDir/data/dgrp2dm6/tables\n",
      "chr2L_exons_downsampled.pkl         chr3R_short_introns_downsampled.pkl\n",
      "chr2L_short_introns_downsampled.pkl dgrp2dm6_chr2L_rooted_ann_table.tsv\n",
      "chr2R_exons_downsampled.pkl         dgrp2dm6_chr2R_rooted_ann_table.tsv\n",
      "chr2R_short_introns_downsampled.pkl dgrp2dm6_chr3L_rooted_ann_table.tsv\n",
      "chr3L_exons_downsampled.pkl         dgrp2dm6_chr3R_rooted_ann_table.tsv\n",
      "chr3L_short_introns_downsampled.pkl dgrp2dm6_chr4_rooted_ann_table.tsv\n",
      "chr3R_exons_downsampled.pkl         dgrp2dm6_chrX_rooted_ann_table.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../../dgrp2dm6/tables\n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the `.tsv` file for each chromosome (except for the __chrom4__ and __chromX__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files with pd.read_table()\n",
    "chr2L_table = pd.read_table(\"dgrp2dm6_chr2L_rooted_ann_table.tsv\")\n",
    "chr2R_table = pd.read_table(\"dgrp2dm6_chr2R_rooted_ann_table.tsv\")\n",
    "chr3L_table = pd.read_table(\"dgrp2dm6_chr3L_rooted_ann_table.tsv\")\n",
    "chr3R_table = pd.read_table(\"dgrp2dm6_chr3R_rooted_ann_table.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of SNPs in each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 910877, chr2R = 740993, chr3L = 896257, chr3R = 884024 SNPs!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_table.shape[0], chr2R_table.shape[0], chr3L_table.shape[0], chr3R_table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>refcount</th>\n",
       "      <th>altcount</th>\n",
       "      <th>refflank</th>\n",
       "      <th>altflank</th>\n",
       "      <th>refcodon</th>\n",
       "      <th>...</th>\n",
       "      <th>snpeff_trnscid</th>\n",
       "      <th>sift_trnscid</th>\n",
       "      <th>sift_geneid</th>\n",
       "      <th>sift_genename</th>\n",
       "      <th>sift_region</th>\n",
       "      <th>sift_vartype</th>\n",
       "      <th>sifts_core</th>\n",
       "      <th>sift_median</th>\n",
       "      <th>sift_pred</th>\n",
       "      <th>deleteriousness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>4998</td>\n",
       "      <td>2L_4998_SNP</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>TAATGACTG</td>\n",
       "      <td>TAATAACTG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5002</td>\n",
       "      <td>2L_5002_SNP</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>GACTGCCTC</td>\n",
       "      <td>GACTTCCTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5039</td>\n",
       "      <td>2L_5039_SNP</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>AAATCGACA</td>\n",
       "      <td>AAATTAACA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5040</td>\n",
       "      <td>2L_5040_SNP</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>AATCGACAA</td>\n",
       "      <td>AATTAACAA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5092</td>\n",
       "      <td>2L_5092_SNP</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>TTTTCTCTC</td>\n",
       "      <td>TTTTTTCAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom   pos           id ref alt  refcount  altcount   refflank   altflank  \\\n",
       "0  chr2L  4998  2L_4998_SNP   G   A       117         5  TAATGACTG  TAATAACTG   \n",
       "1  chr2L  5002  2L_5002_SNP   G   T       127         1  GACTGCCTC  GACTTCCTC   \n",
       "2  chr2L  5039  2L_5039_SNP   C   T         1       118  AAATCGACA  AAATTAACA   \n",
       "3  chr2L  5040  2L_5040_SNP   G   A         1       118  AATCGACAA  AATTAACAA   \n",
       "4  chr2L  5092  2L_5092_SNP   C   T         6       119  TTTTCTCTC  TTTTTTCAC   \n",
       "\n",
       "  refcodon  ... snpeff_trnscid sift_trnscid sift_geneid sift_genename  \\\n",
       "0      NaN  ...    FBtr0475186          NaN         NaN           NaN   \n",
       "1      NaN  ...    FBtr0475186          NaN         NaN           NaN   \n",
       "2      NaN  ...    FBtr0475186          NaN         NaN           NaN   \n",
       "3      NaN  ...    FBtr0475186          NaN         NaN           NaN   \n",
       "4      NaN  ...    FBtr0475186          NaN         NaN           NaN   \n",
       "\n",
       "  sift_region sift_vartype sifts_core sift_median sift_pred deleteriousness  \n",
       "0         NaN          NaN        NaN         NaN       NaN             NaN  \n",
       "1         NaN          NaN        NaN         NaN       NaN             NaN  \n",
       "2         NaN          NaN        NaN         NaN       NaN             NaN  \n",
       "3         NaN          NaN        NaN         NaN       NaN             NaN  \n",
       "4         NaN          NaN        NaN         NaN       NaN             NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at chr2R\n",
    "chr2L_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Random sampling of the alternative allele__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total number of haplotypes for each SNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a total count column to all datasets:\n",
    "chr2L_table['totalcount'] = chr2L_table['refcount'] + chr2L_table['altcount']\n",
    "chr2R_table['totalcount'] = chr2R_table['refcount'] + chr2R_table['altcount']\n",
    "chr3L_table['totalcount'] = chr3L_table['refcount'] + chr3L_table['altcount']\n",
    "chr3R_table['totalcount'] = chr3R_table['refcount'] + chr3R_table['altcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>refcount</th>\n",
       "      <th>altcount</th>\n",
       "      <th>refflank</th>\n",
       "      <th>altflank</th>\n",
       "      <th>refcodon</th>\n",
       "      <th>...</th>\n",
       "      <th>sift_trnscid</th>\n",
       "      <th>sift_geneid</th>\n",
       "      <th>sift_genename</th>\n",
       "      <th>sift_region</th>\n",
       "      <th>sift_vartype</th>\n",
       "      <th>sifts_core</th>\n",
       "      <th>sift_median</th>\n",
       "      <th>sift_pred</th>\n",
       "      <th>deleteriousness</th>\n",
       "      <th>totalcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>4998</td>\n",
       "      <td>2L_4998_SNP</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>TAATGACTG</td>\n",
       "      <td>TAATAACTG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5002</td>\n",
       "      <td>2L_5002_SNP</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>GACTGCCTC</td>\n",
       "      <td>GACTTCCTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5039</td>\n",
       "      <td>2L_5039_SNP</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>AAATCGACA</td>\n",
       "      <td>AAATTAACA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5040</td>\n",
       "      <td>2L_5040_SNP</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>AATCGACAA</td>\n",
       "      <td>AATTAACAA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5092</td>\n",
       "      <td>2L_5092_SNP</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>TTTTCTCTC</td>\n",
       "      <td>TTTTTTCAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom   pos           id ref alt  refcount  altcount   refflank   altflank  \\\n",
       "0  chr2L  4998  2L_4998_SNP   G   A       117         5  TAATGACTG  TAATAACTG   \n",
       "1  chr2L  5002  2L_5002_SNP   G   T       127         1  GACTGCCTC  GACTTCCTC   \n",
       "2  chr2L  5039  2L_5039_SNP   C   T         1       118  AAATCGACA  AAATTAACA   \n",
       "3  chr2L  5040  2L_5040_SNP   G   A         1       118  AATCGACAA  AATTAACAA   \n",
       "4  chr2L  5092  2L_5092_SNP   C   T         6       119  TTTTCTCTC  TTTTTTCAC   \n",
       "\n",
       "  refcodon  ... sift_trnscid sift_geneid sift_genename sift_region  \\\n",
       "0      NaN  ...          NaN         NaN           NaN         NaN   \n",
       "1      NaN  ...          NaN         NaN           NaN         NaN   \n",
       "2      NaN  ...          NaN         NaN           NaN         NaN   \n",
       "3      NaN  ...          NaN         NaN           NaN         NaN   \n",
       "4      NaN  ...          NaN         NaN           NaN         NaN   \n",
       "\n",
       "  sift_vartype sifts_core sift_median sift_pred deleteriousness totalcount  \n",
       "0          NaN        NaN         NaN       NaN             NaN        122  \n",
       "1          NaN        NaN         NaN       NaN             NaN        128  \n",
       "2          NaN        NaN         NaN       NaN             NaN        119  \n",
       "3          NaN        NaN         NaN       NaN             NaN        119  \n",
       "4          NaN        NaN         NaN       NaN             NaN        125  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at chr2L\n",
    "chr2L_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove SNPs if the totalcount < 160. This defines a lower bound for the random sampling (the minimum number of haplotypes used to sample alternative alleles to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the lower bound for the number of haplotypes\n",
    "min_number_of_haplotypes = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_table = chr2L_table[chr2L_table['totalcount'] >= min_number_of_haplotypes]\n",
    "chr2R_table = chr2R_table[chr2R_table['totalcount'] >= min_number_of_haplotypes]\n",
    "chr3L_table = chr3L_table[chr3L_table['totalcount'] >= min_number_of_haplotypes]\n",
    "chr3R_table = chr3R_table[chr3R_table['totalcount'] >= min_number_of_haplotypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 887541, chr2R = 723473, chr3L = 877098, chr3R = 868475 SNPs!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_table.shape[0], chr2R_table.shape[0], chr3L_table.shape[0], chr3R_table.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, random sample the alternative allele count. The function will update the input DataFrame with new values for the total counts, reference, and alternative allele counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randmly sample alternative allele counts and update the number of total counts in the table\n",
    "chr2L_table_sampled = ramdomly_sample_haplotypes(chr2L_table, min_number_of_haplotypes)\n",
    "chr2R_table_sampled = ramdomly_sample_haplotypes(chr2R_table, min_number_of_haplotypes)\n",
    "chr3L_table_sampled = ramdomly_sample_haplotypes(chr3L_table, min_number_of_haplotypes)\n",
    "chr3R_table_sampled = ramdomly_sample_haplotypes(chr3R_table, min_number_of_haplotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Subset SNPs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Subset each chromosome to retain only:__\n",
    "- `SNPs in short-introns`;\n",
    "- `Synonymous SNPs`;\n",
    "- `Non-synonymous SNPs`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(1) Subset to retain only SNPs annotated as introns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chr2L_introns = chr2L_table_sampled[(chr2L_table_sampled['effect'] == \"INTRON\")]\n",
    "chr2R_introns = chr2R_table_sampled[(chr2R_table_sampled['effect'] == \"INTRON\")]\n",
    "chr3L_introns = chr3L_table_sampled[(chr3L_table_sampled['effect'] == \"INTRON\")]\n",
    "chr3R_introns = chr3R_table_sampled[(chr3R_table_sampled['effect'] == \"INTRON\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 159682, chr2R = 122286, chr3L = 164146, chr3R = 184795 SNPs!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_introns.shape[0], chr2R_introns.shape[0], chr3L_introns.shape[0], chr3R_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(2)Keep only short intronic SNPs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each chromosome, retain only SNPs in `short introns`. To do that, you need to identify the short-intros in Dm6 genome and head/tail the sequence to remove head and trailing 8bp from each short-intron. These extremes migh be under selection constraints. Download the intron regions as `.BED` file from [here](https://genome.ucsc.edu/cgi-bin/hgTables). Select *D. melanogaster* assembly known as *Dm6* (Aug. 2014, BDGP Release 6 + ISO 1 MT/dm6). Define the region of interest as `genome`, select the output format as `BED` and name it. In the next page, select only `Introns plus 0`, then hit `Get BED`. Now you are ready to go. The next step is to create a Pandas DataFrame with short introns intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/WorkDir/data/dgrp2dm6/reference\n",
      "dm6.fa                              dmel-all-chromosome-r6.52.fasta.fai\n",
      "dm6.fa.fai                          dmel-all-chromosome-r6.52.fasta.gz\n",
      "dm6_introns.bed                     dmel-all-r6.52.gff\n",
      "dm6_short_introns.bed               dmel-all-r6.52.gff.gz\n",
      "dmel-all-chromosome-r6.52.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../reference/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_001201797.2_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_001201795.2_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_164812.5_intron_4_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_205936.3_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_205935.3_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2                                          3  4  5\n",
       "0  chr2L  8387838  8387882  NM_001201797.2_intron_5_0_chr2L_8387832_f  0  +\n",
       "1  chr2L  8387838  8387882  NM_001201795.2_intron_5_0_chr2L_8387832_f  0  +\n",
       "2  chr2L  8387838  8387882     NM_164812.5_intron_4_0_chr2L_8387832_f  0  +\n",
       "3  chr2L  8387838  8387882     NM_205936.3_intron_5_0_chr2L_8387832_f  0  +\n",
       "4  chr2L  8387838  8387882     NM_205935.3_intron_5_0_chr2L_8387832_f  0  +"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_introns = filter_short_introns_from_bed(\"dm6_introns.bed\", \n",
    "                                              \"dm6_short_introns.bed\", \n",
    "                                              [\"chr2L\", \"chr2R\", \"chr3L\", \"chr3R\"],\n",
    "                                              short_intron_size=86,\n",
    "                                              trailling_size=8)\n",
    "short_introns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the filter based on the BED file intervals (to make sure to only keep `short-intronic` SNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only short-intons SNPs.\n",
    "chr2L_short_introns = filter_snps_by_interval(chr2L_introns, short_introns)\n",
    "chr2R_short_introns = filter_snps_by_interval(chr2R_introns, short_introns)\n",
    "chr3L_short_introns = filter_snps_by_interval(chr3L_introns, short_introns)\n",
    "chr3R_short_introns = filter_snps_by_interval(chr3R_introns, short_introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump these DataFrames as pickle files to avoid re-running it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/WorkDir/data/dgrp2dm6\n",
      "\u001b[1m\u001b[36mannotations[dont_use-this_is_old_script]\u001b[m\u001b[m\n",
      "dgrp2dm6_chr2L_rooted.vcf\n",
      "dgrp2dm6_chr2R_rooted.vcf\n",
      "dgrp2dm6_chr3L_rooted.vcf\n",
      "dgrp2dm6_chr3R_rooted.vcf\n",
      "dgrp2dm6_chr4_rooted.vcf\n",
      "dgrp2dm6_chrX_rooted.vcf\n",
      "\u001b[1m\u001b[36mintervals\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mreference\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36msfss\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36msift4g\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36msnpeff\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mtables\u001b[m\u001b[m\n",
      "vcfs\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle chrm short-introns DataFrames\n",
    "# chr2L_short_introns.to_pickle(\"tables/chr2L_short_introns_sampled.pkl\")\n",
    "# chr2R_short_introns.to_pickle(\"tables/chr2R_short_introns_sampled.pkl\")\n",
    "# chr3L_short_introns.to_pickle(\"tables/chr3L_short_introns_sampled.pkl\")\n",
    "# chr3R_short_introns.to_pickle(\"tables/chr3R_short_introns_sampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled chrm short-introns DataFrames\n",
    "# chr2L_short_introns = pd.read_pickle(\"tables/chr2L_short_introns_sampled.pkl\")\n",
    "# chr2R_short_introns = pd.read_pickle(\"tables/chr2R_short_introns_sampled.pkl\")\n",
    "# chr3L_short_introns = pd.read_pickle(\"tables/chr3L_short_introns_sampled.pkl\")\n",
    "# chr3R_short_introns = pd.read_pickle(\"tables/chr3R_short_introns_sampled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many short-introns SNPs were retained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 1478, chr2R = 1318, chr3L = 1075, chr3R = 1477 SNPs!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_short_introns.shape[0], chr2R_short_introns.shape[0], chr3L_short_introns.shape[0], chr3R_short_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(3) Take synonymous and non-synonymous SNPs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_exons = chr2L_table_sampled[(chr2L_table_sampled['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr2L_table_sampled['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr2R_exons = chr2R_table_sampled[(chr2R_table_sampled['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr2R_table_sampled['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3L_exons = chr3L_table_sampled[(chr3L_table_sampled['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr3L_table_sampled['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3R_exons = chr3R_table_sampled[(chr3R_table_sampled['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr3R_table_sampled['effect'] == \"SYNONYMOUS_CODING\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle chrm exons DataFrames\n",
    "# chr2L_exons.to_pickle(\"tables/chr2L_exons_sampled.pkl\")\n",
    "# chr2R_exons.to_pickle(\"tables/chr2R_exons_sampled.pkl\")\n",
    "# chr3L_exons.to_pickle(\"tables/chr3L_exons_sampled.pkl\")\n",
    "# chr3R_exons.to_pickle(\"tables/chr3R_exons_sampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled chrm exons DataFrames\n",
    "# chr2L_exons = pd.read_pickle(\"tables/chr2L_exons_sampled.pkl\")\n",
    "# chr2R_exons = pd.read_pickle(\"tables/chr2R_exons_sampled.pkl\")\n",
    "# chr3L_exons = pd.read_pickle(\"tables/chr3L_exons_sampled.pkl\")\n",
    "# chr3R_exons = pd.read_pickle(\"tables/chr3R_exons_sampled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same on the other chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 118921, chr2R = 113115, chr3L = 113590, chr3R = 117815 SNPs!'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_exons.shape[0], chr2R_exons.shape[0], chr3L_exons.shape[0], chr3R_exons.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Get the SFSs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For introns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_short_introns_sfs = create_unfolded_sfs_from_df(chr2L_short_introns, \"altcount\", min_number_of_haplotypes)\n",
    "chr2R_short_introns_sfs = create_unfolded_sfs_from_df(chr2R_short_introns, \"altcount\", min_number_of_haplotypes)\n",
    "chr3L_short_introns_sfs = create_unfolded_sfs_from_df(chr3L_short_introns, \"altcount\", min_number_of_haplotypes)\n",
    "chr3R_short_introns_sfs = create_unfolded_sfs_from_df(chr3R_short_introns, \"altcount\", min_number_of_haplotypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then combined each chromosome short-introns SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_introns_sfs_array = np.array([\n",
    "    chr2L_short_introns_sfs,\n",
    "    chr2R_short_introns_sfs,\n",
    "    chr3L_short_introns_sfs,\n",
    "    chr3R_short_introns_sfs\n",
    "])\n",
    "\n",
    "short_introns_sfs = np.sum(short_introns_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the synonymous SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_synonymous = chr2L_exons[(chr2L_exons['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr2R_synonymous = chr2R_exons[(chr2R_exons['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3L_synonymous = chr3L_exons[(chr3L_exons['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3R_synonymous = chr3R_exons[(chr3R_exons['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "\n",
    "synonymous_sfs_array = np.array([\n",
    "    create_unfolded_sfs_from_df(chr2L_synonymous, \"altcount\", min_number_of_haplotypes),\n",
    "    create_unfolded_sfs_from_df(chr2R_synonymous, \"altcount\", min_number_of_haplotypes),\n",
    "    create_unfolded_sfs_from_df(chr3L_synonymous, \"altcount\", min_number_of_haplotypes),\n",
    "    create_unfolded_sfs_from_df(chr3R_synonymous, \"altcount\", min_number_of_haplotypes)\n",
    "])\n",
    "\n",
    "synonymous_sfs = np.sum(synonymous_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for non-synonymous ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_nonsynonymous = chr2L_exons[(chr2L_exons['effect'] == \"NON_SYNONYMOUS_CODING\")]\n",
    "chr2R_nonsynonymous = chr2R_exons[(chr2R_exons['effect'] == \"NON_SYNONYMOUS_CODING\")]\n",
    "chr3L_nonsynonymous = chr3L_exons[(chr3L_exons['effect'] == \"NON_SYNONYMOUS_CODING\")]\n",
    "chr3R_nonsynonymous = chr3R_exons[(chr3R_exons['effect'] == \"NON_SYNONYMOUS_CODING\")]\n",
    "\n",
    "nonsynonymous_sfs_array = np.array([\n",
    "    create_unfolded_sfs_from_df(chr2L_nonsynonymous, \"altcount\", min_number_of_haplotypes),\n",
    "    create_unfolded_sfs_from_df(chr2R_nonsynonymous, \"altcount\", min_number_of_haplotypes),\n",
    "    create_unfolded_sfs_from_df(chr3L_nonsynonymous, \"altcount\", min_number_of_haplotypes),\n",
    "    create_unfolded_sfs_from_df(chr3R_nonsynonymous, \"altcount\", min_number_of_haplotypes)\n",
    "])\n",
    "\n",
    "nonsynonymous_sfs = np.sum(nonsynonymous_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Fold the SFSs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_introns_sfs_folded = fold_sfs(short_introns_sfs)\n",
    "synonymous_sfs_folded = fold_sfs(synonymous_sfs)\n",
    "nonsynonymous_sfs_folded = fold_sfs(nonsynonymous_sfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the three SFSs to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/WorkDir/data/dgrp2dm6/sfss\n",
      "\u001b[1m\u001b[36mno-pairing\u001b[m\u001b[m \u001b[1m\u001b[36mpaired\u001b[m\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd sfss/\n",
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sfs_file = \"no-pairing/dgrp2_sfs_si_nopairing_sampled_folded.txt\"\n",
    "\n",
    "with open(output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Introns, synonymous, and nonsynonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in short_introns_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in synonymous_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in nonsynonymous_sfs_folded) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Pair neutral and non-neutral SNPs by mutational context__\n",
    "\n",
    "Now that we had a simple way to get the SFSs, we are going to add some complexities and pair neutral and non-neutral SNPs by their mutational context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mno-pairing\u001b[m\u001b[m \u001b[1m\u001b[36mpaired\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove SNPs that are close to each other, as they might cause ambiguity on the sequence category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Short-introns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True for SNPs far apart and False otherwise, and insert a column on each chromosome DataFrame:\n",
    "# Insert the new column at position 3\n",
    "chr2L_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2L_short_introns[\"pos\"])))\n",
    "chr2R_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2R_short_introns[\"pos\"])))\n",
    "chr3L_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3L_short_introns[\"pos\"])))\n",
    "chr3R_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3R_short_introns[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_short_introns = chr2L_short_introns[chr2L_short_introns['pos_to_keep'] == True]\n",
    "chr2R_short_introns = chr2R_short_introns[chr2R_short_introns['pos_to_keep'] == True]\n",
    "chr3L_short_introns = chr3L_short_introns[chr3L_short_introns['pos_to_keep'] == True]\n",
    "chr3R_short_introns = chr3R_short_introns[chr3R_short_introns['pos_to_keep'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 1196, chr2R = 1077, chr3L = 891, chr3R = 1220 SNPs!'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_short_introns.shape[0], chr2R_short_introns.shape[0], chr3L_short_introns.shape[0], chr3R_short_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Exons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True for SNPs far apart and False otherwise, and insert a column on each chromosome DataFrame:\n",
    "# Insert the new column at position 3\n",
    "chr2L_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2L_exons[\"pos\"])))\n",
    "chr2R_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2R_exons[\"pos\"])))\n",
    "chr3L_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3L_exons[\"pos\"])))\n",
    "chr3R_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3R_exons[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_exons = chr2L_exons[chr2L_exons['pos_to_keep'] == True]\n",
    "chr2R_exons = chr2R_exons[chr2R_exons['pos_to_keep'] == True]\n",
    "chr3L_exons = chr3L_exons[chr3L_exons['pos_to_keep'] == True]\n",
    "chr3R_exons = chr3R_exons[chr3R_exons['pos_to_keep'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 111133, chr2R = 105929, chr3L = 106496, chr3R = 110931 SNPs!'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_exons.shape[0], chr2R_exons.shape[0], chr3L_exons.shape[0], chr3R_exons.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the sequence category for each SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the new column at position 9\n",
    "# For introns:\n",
    "chr2L_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr2L_short_introns))\n",
    "chr2R_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr2R_short_introns))\n",
    "chr3L_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr3L_short_introns))\n",
    "chr3R_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr3R_short_introns))\n",
    "\n",
    "# For exons:\n",
    "chr2L_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr2L_exons))\n",
    "chr2R_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr2R_exons))\n",
    "chr3L_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr3L_exons))\n",
    "chr3R_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr3R_exons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the sequence category dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['AA/CA', 'AC/AA'], 2: ['CA/CA', 'CC/AA'], 3: ['GA/CA', 'GC/AA'], 4: ['TA/CA', 'TC/AA'], 5: ['AA/CC', 'AC/AC'], 6: ['CA/CC', 'CC/AC'], 7: ['GA/CC', 'GC/AC'], 8: ['TA/CC', 'TC/AC'], 9: ['AA/CG', 'AC/AG'], 10: ['CA/CG', 'CC/AG'], 11: ['GA/CG', 'GC/AG'], 12: ['TA/CG', 'TC/AG'], 13: ['AA/CT', 'AC/AT'], 14: ['CA/CT', 'CC/AT'], 15: ['GA/CT', 'GC/AT'], 16: ['TA/CT', 'TC/AT'], 17: ['AA/GA', 'AG/AA'], 18: ['CA/GA', 'CG/AA'], 19: ['GA/GA', 'GG/AA'], 20: ['TA/GA', 'TG/AA'], 21: ['AA/GC', 'AG/AC'], 22: ['CA/GC', 'CG/AC'], 23: ['GA/GC', 'GG/AC'], 24: ['TA/GC', 'TG/AC'], 25: ['AA/GG', 'AG/AG'], 26: ['CA/GG', 'CG/AG'], 27: ['GA/GG', 'GG/AG'], 28: ['TA/GG', 'TG/AG'], 29: ['AA/GT', 'AG/AT'], 30: ['CA/GT', 'CG/AT'], 31: ['GA/GT', 'GG/AT'], 32: ['TA/GT', 'TG/AT'], 33: ['AA/TA', 'AT/AA'], 34: ['CA/TA', 'CT/AA'], 35: ['GA/TA', 'GT/AA'], 36: ['TA/TA', 'TT/AA'], 37: ['AA/TC', 'AT/AC'], 38: ['CA/TC', 'CT/AC'], 39: ['GA/TC', 'GT/AC'], 40: ['TA/TC', 'TT/AC'], 41: ['AA/TG', 'AT/AG'], 42: ['CA/TG', 'CT/AG'], 43: ['GA/TG', 'GT/AG'], 44: ['TA/TG', 'TT/AG'], 45: ['AA/TT', 'AT/AT'], 46: ['CA/TT', 'CT/AT'], 47: ['GA/TT', 'GT/AT'], 48: ['TA/TT', 'TT/AT'], 49: ['AC/GA', 'AG/CA'], 50: ['CC/GA', 'CG/CA'], 51: ['GC/GA', 'GG/CA'], 52: ['TC/GA', 'TG/CA'], 53: ['AC/GC', 'AG/CC'], 54: ['CC/GC', 'CG/CC'], 55: ['GC/GC', 'GG/CC'], 56: ['TC/GC', 'TG/CC'], 57: ['AC/GG', 'AG/CG'], 58: ['CC/GG', 'CG/CG'], 59: ['GC/GG', 'GG/CG'], 60: ['TC/GG', 'TG/CG'], 61: ['AC/GT', 'AG/CT'], 62: ['CC/GT', 'CG/CT'], 63: ['GC/GT', 'GG/CT'], 64: ['TC/GT', 'TG/CT'], 65: ['AC/TA', 'AT/CA'], 66: ['CC/TA', 'CT/CA'], 67: ['GC/TA', 'GT/CA'], 68: ['TC/TA', 'TT/CA'], 69: ['AC/TC', 'AT/CC'], 70: ['CC/TC', 'CT/CC'], 71: ['GC/TC', 'GT/CC'], 72: ['TC/TC', 'TT/CC'], 73: ['AC/TG', 'AT/CG'], 74: ['CC/TG', 'CT/CG'], 75: ['GC/TG', 'GT/CG'], 76: ['TC/TG', 'TT/CG'], 77: ['AC/TT', 'AT/CT'], 78: ['CC/TT', 'CT/CT'], 79: ['GC/TT', 'GT/CT'], 80: ['TC/TT', 'TT/CT'], 81: ['AG/TA', 'AT/GA'], 82: ['CG/TA', 'CT/GA'], 83: ['GG/TA', 'GT/GA'], 84: ['TG/TA', 'TT/GA'], 85: ['AG/TC', 'AT/GC'], 86: ['CG/TC', 'CT/GC'], 87: ['GG/TC', 'GT/GC'], 88: ['TG/TC', 'TT/GC'], 89: ['AG/TG', 'AT/GG'], 90: ['CG/TG', 'CT/GG'], 91: ['GG/TG', 'GT/GG'], 92: ['TG/TG', 'TT/GG'], 93: ['AG/TT', 'AT/GT'], 94: ['CG/TT', 'CT/GT'], 95: ['GG/TT', 'GT/GT'], 96: ['TG/TT', 'TT/GT']}\n"
     ]
    }
   ],
   "source": [
    "# First create a object for the sequence categories dictionary\n",
    "sequence_categories_dict = create_sequence_categories_dict()\n",
    "print(sequence_categories_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create three dictionaries for each chromosome\n",
    "# For introns\n",
    "chr2L_short_introns_seqclasses = create_snp_dict_wrapper(chr2L_short_introns, sequence_categories_dict, \"introns\")\n",
    "chr2R_short_introns_seqclasses = create_snp_dict_wrapper(chr2R_short_introns, sequence_categories_dict, \"introns\")\n",
    "chr3L_short_introns_seqclasses = create_snp_dict_wrapper(chr3L_short_introns, sequence_categories_dict, \"introns\")\n",
    "chr3R_short_introns_seqclasses = create_snp_dict_wrapper(chr3R_short_introns, sequence_categories_dict, \"introns\")\n",
    "\n",
    "# For exons\n",
    "chr2L_nonsyns_seqclasses, chr2L_syns_seqclasses = create_snp_dict_wrapper(chr2L_exons, sequence_categories_dict, \"exons\")\n",
    "chr2R_nonsyns_seqclasses, chr2R_syns_seqclasses = create_snp_dict_wrapper(chr2R_exons, sequence_categories_dict, \"exons\")\n",
    "chr3L_nonsyns_seqclasses, chr3L_syns_seqclasses = create_snp_dict_wrapper(chr3L_exons, sequence_categories_dict, \"exons\")\n",
    "chr3R_nonsyns_seqclasses, chr3R_syns_seqclasses = create_snp_dict_wrapper(chr3R_exons, sequence_categories_dict, \"exons\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find mutational context pairs and get the SFSs\n",
    "Now, find the pairs and obtain the SFSs for each member of the pair. These are the valid pairs we are looking to have:\n",
    "- `short-intron SNP` and `non-synonymous SNPs`;\n",
    "- `short-intron SNP` and `synonymous SNPs`;\n",
    "- `synonymous SNP` and `non-synonymous SNPs` (maybe?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `short-intron SNP` and `non-synonymous SNPs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs of SNPs that are closest to each other\n",
    "chr2L_si_nonsyn_pairs_si, chr2L_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2L_short_introns_seqclasses, chr2L_nonsyns_seqclasses)\n",
    "chr2R_si_nonsyn_pairs_si, chr2R_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2R_short_introns_seqclasses, chr2R_nonsyns_seqclasses)\n",
    "chr3L_si_nonsyn_pairs_si, chr3L_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3L_short_introns_seqclasses, chr3L_nonsyns_seqclasses)\n",
    "chr3R_si_nonsyn_pairs_si, chr3R_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3R_short_introns_seqclasses, chr3R_nonsyns_seqclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n"
     ]
    }
   ],
   "source": [
    "# Get the SFS for the short introns SNPs\n",
    "# Remember: the data is now sampled, so the max_sample_size means the lower bound set to 160.\n",
    "# Use the imputed argument, knowing that the data was sampled.\n",
    "short_introns_paired_nonsyn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_nonsyn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_nonsyn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_nonsyn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_nonsyn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "short_introns_paired_nonsyn_seqclasses_sfs_folded = np.sum(short_introns_paired_nonsyn_sfs_seqclasses_array, 0).tolist()\n",
    "\n",
    "# Get the SFS for the nonsynonymous SNPs\n",
    "nonsynonymous_paired_si_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "nonsynonymous_paired_si_seqclasses_sfs_folded = np.sum(nonsynonymous_paired_si_sfs_seqclasses_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pairs to a file\n",
    "si_nonsyn_pair_output_sfs_file = \"paired/dgrp2_sfs_si_paired_with_nonsynynous_sampled_folded.txt\"\n",
    "\n",
    "with open(si_nonsyn_pair_output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Introns and nonsynonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in short_introns_paired_nonsyn_seqclasses_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in nonsynonymous_paired_si_seqclasses_sfs_folded) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `short-intron SNP` and `synonymous SNPs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs of SNPs that are closest to each other\n",
    "chr2L_si_syn_pairs_si, chr2L_si_syn_pairs_syn = find_closest_snp_pairs(chr2L_short_introns_seqclasses, chr2L_syns_seqclasses)\n",
    "chr2R_si_syn_pairs_si, chr2R_si_syn_pairs_syn = find_closest_snp_pairs(chr2R_short_introns_seqclasses, chr2R_syns_seqclasses)\n",
    "chr3L_si_syn_pairs_si, chr3L_si_syn_pairs_syn = find_closest_snp_pairs(chr3L_short_introns_seqclasses, chr3L_syns_seqclasses)\n",
    "chr3R_si_syn_pairs_si, chr3R_si_syn_pairs_syn = find_closest_snp_pairs(chr3R_short_introns_seqclasses, chr3R_syns_seqclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n"
     ]
    }
   ],
   "source": [
    "# Get the SFS for the short introns SNPs\n",
    "short_introns_paired_syn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_syn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_syn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_syn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_syn_pairs_si, \"imputed\", min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "short_introns_paired_syn_seqclasses_sfs_folded = np.sum(short_introns_paired_syn_sfs_seqclasses_array, 0).tolist()\n",
    "\n",
    "# Get the SFS for the synonymous SNPs\n",
    "synonymous_paired_si_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_syn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_syn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_syn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_syn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "synonymous_paired_si_seqclasses_sfs_folded = np.sum(synonymous_paired_si_sfs_seqclasses_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pairs to a file\n",
    "si_syn_pair_output_sfs_file = \"paired/dgrp2_sfs_si_paired_with_synynous_sampled_folded.txt\"\n",
    "\n",
    "with open(si_syn_pair_output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Introns and synonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in short_introns_paired_syn_seqclasses_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in synonymous_paired_si_seqclasses_sfs_folded) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `synonymous SNP` and `non-synonymous SNPs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs of SNPs that are closest to each other\n",
    "chr2L_syn_nonsyn_pairs_syn, chr2L_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2L_syns_seqclasses, chr2L_nonsyns_seqclasses)\n",
    "chr2R_syn_nonsyn_pairs_syn, chr2R_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2R_syns_seqclasses, chr2R_nonsyns_seqclasses)\n",
    "chr3L_syn_nonsyn_pairs_syn, chr3L_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3L_syns_seqclasses, chr3L_nonsyns_seqclasses)\n",
    "chr3R_syn_nonsyn_pairs_syn, chr3R_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3R_syns_seqclasses, chr3R_nonsyns_seqclasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n",
      "Working with imputed data...\n"
     ]
    }
   ],
   "source": [
    "# Get the SFS for the synonymous SNPs\n",
    "synonymous_paired_nonsyn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_syn_nonsyn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_syn_nonsyn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_syn_nonsyn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_syn_nonsyn_pairs_syn, \"imputed\", min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "synonymous_paired_nonsyn_seqclasses_sfs_folded = np.sum(synonymous_paired_nonsyn_sfs_seqclasses_array, 0).tolist()\n",
    "\n",
    "# Get the SFS for the nonsynonymous SNPs\n",
    "nonsynonymous_paired_syn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_syn_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_syn_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_syn_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_syn_nonsyn_pairs_nonsyn, \"imputed\", min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "nonsynonymous_paired_syn_seqclasses_sfs_folded = np.sum(nonsynonymous_paired_syn_sfs_seqclasses_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pairs to a file\n",
    "syn_nonsyn_pair_output_sfs_file = \"paired/dgrp2_sfs_synonymous_paired_with_nonsynynous_sampled_folded.txt\"\n",
    "\n",
    "with open(syn_nonsyn_pair_output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Synonymous and nonsynonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in synonymous_paired_nonsyn_seqclasses_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in nonsynonymous_paired_syn_seqclasses_sfs_folded) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
