{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Pipeline 2: SNP processing with downsampling__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Requirements__\n",
    "- a python environment (installed with conda for example);\n",
    "- .TSV files from the obtained with pipeline 1;\n",
    "- python `subprocess`;\n",
    "- python `Numpy`;\n",
    "- python `Pandas`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from snp_utils import filter_short_introns_from_bed, filter_snps_by_interval, create_snp_total_counts_dict\n",
    "from sfs_utils import create_sfs_dict, downsample_sfs_in_dict\n",
    "from mutational_context_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Import the tables into Pandas__\n",
    "\n",
    "We are going to use pandas to import the SNP table. Pandas is a great (if used with cauting) Python package built on Numpy which allows easy dataFrame manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/DGN/dpgp3/masked/vcfs/tables\n",
      "ZI_chr2L_ann_table.tsv          chr2R_short_introns_imputed.pkl\n",
      "ZI_chr2R_ann_table.tsv          chr2R_short_introns_sampled.pkl\n",
      "ZI_chr3L_ann_table.tsv          chr3L_exons_imputed.pkl\n",
      "ZI_chr3R_ann_table.tsv          chr3L_exons_sampled.pkl\n",
      "chr2L_exons_imputed.pkl         chr3L_short_introns_imputed.pkl\n",
      "chr2L_exons_sampled.pkl         chr3L_short_introns_sampled.pkl\n",
      "chr2L_short_introns_imputed.pkl chr3R_exons_imputed.pkl\n",
      "chr2L_short_introns_sampled.pkl chr3R_exons_sampled.pkl\n",
      "chr2R_exons_imputed.pkl         chr3R_short_introns_imputed.pkl\n",
      "chr2R_exons_sampled.pkl         chr3R_short_introns_sampled.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../../masked/vcfs/tables/\n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the `.tsv` file for each chromosome (except for the __chrom4__ and __chromX__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files with pd.read_table()\n",
    "chr2L_table = pd.read_table(\"ZI_chr2L_ann_table.tsv\")\n",
    "chr2R_table = pd.read_table(\"ZI_chr2R_ann_table.tsv\")\n",
    "chr3L_table = pd.read_table(\"ZI_chr3L_ann_table.tsv\")\n",
    "chr3R_table = pd.read_table(\"ZI_chr3R_ann_table.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of SNPs in each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 2016260, chr2R = 1582937, chr3L = 1795061, chr3R = 2087683 SNPs!'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_table.shape[0], chr2R_table.shape[0], chr3L_table.shape[0], chr3R_table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>refcount</th>\n",
       "      <th>altcount</th>\n",
       "      <th>refflank</th>\n",
       "      <th>altflank</th>\n",
       "      <th>refcodon</th>\n",
       "      <th>...</th>\n",
       "      <th>snpeff_trnscid</th>\n",
       "      <th>sift_trnscid</th>\n",
       "      <th>sift_geneid</th>\n",
       "      <th>sift_genename</th>\n",
       "      <th>sift_region</th>\n",
       "      <th>sift_vartype</th>\n",
       "      <th>sifts_core</th>\n",
       "      <th>sift_median</th>\n",
       "      <th>sift_pred</th>\n",
       "      <th>deleteriousness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5090</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>CATTTTCTC</td>\n",
       "      <td>CATTCTCTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5095</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>104</td>\n",
       "      <td>TCTCTCCCA</td>\n",
       "      <td>TCTCACCCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5110</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>AGGGTGAAA</td>\n",
       "      <td>AGGGAGAAA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5118</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>ATATGATCG</td>\n",
       "      <td>ATATTATCG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5140</td>\n",
       "      <td>.</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "      <td>AGTGCCAAC</td>\n",
       "      <td>AGTGTCAAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom   pos id ref alt  refcount  altcount   refflank   altflank refcodon  \\\n",
       "0  chr2L  5090  .   T   C       103         3  CATTTTCTC  CATTCTCTC      NaN   \n",
       "1  chr2L  5095  .   T   A        16       104  TCTCTCCCA  TCTCACCCA      NaN   \n",
       "2  chr2L  5110  .   T   A       130         2  AGGGTGAAA  AGGGAGAAA      NaN   \n",
       "3  chr2L  5118  .   G   T       147         1  ATATGATCG  ATATTATCG      NaN   \n",
       "4  chr2L  5140  .   C   T       158         2  AGTGCCAAC  AGTGTCAAC      NaN   \n",
       "\n",
       "   ... snpeff_trnscid sift_trnscid sift_geneid sift_genename sift_region  \\\n",
       "0  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "1  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "2  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "3  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "4  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "\n",
       "  sift_vartype sifts_core sift_median sift_pred deleteriousness  \n",
       "0          NaN        NaN         NaN       NaN             NaN  \n",
       "1          NaN        NaN         NaN       NaN             NaN  \n",
       "2          NaN        NaN         NaN       NaN             NaN  \n",
       "3          NaN        NaN         NaN       NaN             NaN  \n",
       "4          NaN        NaN         NaN       NaN             NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at chr2L\n",
    "chr2L_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Prepare the DataFrame for downsampling__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total number of haplotypes for each SNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a total count column to all datasets:\n",
    "chr2L_table['totalcount'] = chr2L_table['refcount'] + chr2L_table['altcount']\n",
    "chr2R_table['totalcount'] = chr2R_table['refcount'] + chr2R_table['altcount']\n",
    "chr3L_table['totalcount'] = chr3L_table['refcount'] + chr3L_table['altcount']\n",
    "chr3R_table['totalcount'] = chr3R_table['refcount'] + chr3R_table['altcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>refcount</th>\n",
       "      <th>altcount</th>\n",
       "      <th>refflank</th>\n",
       "      <th>altflank</th>\n",
       "      <th>refcodon</th>\n",
       "      <th>...</th>\n",
       "      <th>sift_trnscid</th>\n",
       "      <th>sift_geneid</th>\n",
       "      <th>sift_genename</th>\n",
       "      <th>sift_region</th>\n",
       "      <th>sift_vartype</th>\n",
       "      <th>sifts_core</th>\n",
       "      <th>sift_median</th>\n",
       "      <th>sift_pred</th>\n",
       "      <th>deleteriousness</th>\n",
       "      <th>totalcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5090</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>CATTTTCTC</td>\n",
       "      <td>CATTCTCTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5095</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>104</td>\n",
       "      <td>TCTCTCCCA</td>\n",
       "      <td>TCTCACCCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5110</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>AGGGTGAAA</td>\n",
       "      <td>AGGGAGAAA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5118</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>ATATGATCG</td>\n",
       "      <td>ATATTATCG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5140</td>\n",
       "      <td>.</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "      <td>AGTGCCAAC</td>\n",
       "      <td>AGTGTCAAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom   pos id ref alt  refcount  altcount   refflank   altflank refcodon  \\\n",
       "0  chr2L  5090  .   T   C       103         3  CATTTTCTC  CATTCTCTC      NaN   \n",
       "1  chr2L  5095  .   T   A        16       104  TCTCTCCCA  TCTCACCCA      NaN   \n",
       "2  chr2L  5110  .   T   A       130         2  AGGGTGAAA  AGGGAGAAA      NaN   \n",
       "3  chr2L  5118  .   G   T       147         1  ATATGATCG  ATATTATCG      NaN   \n",
       "4  chr2L  5140  .   C   T       158         2  AGTGCCAAC  AGTGTCAAC      NaN   \n",
       "\n",
       "   ... sift_trnscid sift_geneid sift_genename sift_region sift_vartype  \\\n",
       "0  ...          NaN         NaN           NaN         NaN          NaN   \n",
       "1  ...          NaN         NaN           NaN         NaN          NaN   \n",
       "2  ...          NaN         NaN           NaN         NaN          NaN   \n",
       "3  ...          NaN         NaN           NaN         NaN          NaN   \n",
       "4  ...          NaN         NaN           NaN         NaN          NaN   \n",
       "\n",
       "  sifts_core sift_median sift_pred deleteriousness totalcount  \n",
       "0        NaN         NaN       NaN             NaN        106  \n",
       "1        NaN         NaN       NaN             NaN        120  \n",
       "2        NaN         NaN       NaN             NaN        132  \n",
       "3        NaN         NaN       NaN             NaN        148  \n",
       "4        NaN         NaN       NaN             NaN        160  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at chr2L\n",
    "chr2L_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove SNPs if the totalcount < 160. This defines a lower bound for downsampling(the minimum number of haplotypes that we are downsampling higher number of haplotypes to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the lower bound for the number of haplotypes\n",
    "min_number_of_haplotypes = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_table = chr2L_table[chr2L_table['totalcount'] >= min_number_of_haplotypes]\n",
    "chr2R_table = chr2R_table[chr2R_table['totalcount'] >= min_number_of_haplotypes]\n",
    "chr3L_table = chr3L_table[chr3L_table['totalcount'] >= min_number_of_haplotypes]\n",
    "chr3R_table = chr3R_table[chr3R_table['totalcount'] >= min_number_of_haplotypes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 1919950, chr2R = 1514541, chr3L = 1719317, chr3R = 2017777 SNPs!'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_table.shape[0], chr2R_table.shape[0], chr3L_table.shape[0], chr3R_table.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Subset SNPs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Subset each chromosome to retain only:__\n",
    "- `SNPs in short-introns`;\n",
    "- `Synonymous SNPs`;\n",
    "- `Non-synonymous SNPs`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(1) Subset to retain only SNPs annotated as introns__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the other chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to retain only SNPs annotated as introns\n",
    "chr2L_introns = chr2L_table[(chr2L_table['effect'] == \"INTRON\")]\n",
    "chr2R_introns = chr2R_table[(chr2R_table['effect'] == \"INTRON\")]\n",
    "chr3L_introns = chr3L_table[(chr3L_table['effect'] == \"INTRON\")]\n",
    "chr3R_introns = chr3R_table[(chr3R_table['effect'] == \"INTRON\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 353457, chr2R = 258584, chr3L = 321868, chr3R = 435809 SNPs!'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_introns.shape[0], chr2R_introns.shape[0], chr3L_introns.shape[0], chr3R_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(2)Keep only short intronic SNPs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each chromosome, retain only SNPs in `short introns`. To do that, you need to identify the short-intros in Dm6 genome and head/tail the sequence to remove head and trailing 8bp from each short-intron. These extremes migh be under selection constraints. Download the intron regions as `.BED` file from [here](https://genome.ucsc.edu/cgi-bin/hgTables). Select *D. melanogaster* assembly known as *Dm6* (Aug. 2014, BDGP Release 6 + ISO 1 MT/dm6). Define the region of interest as `genome`, select the output format as `BED` and name it. In the next page, select only `Introns plus 0`, then hit `Get BED`. Now you are ready to go. The next step is to create a Pandas DataFrame with short introns intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/DGN/reference\n",
      "dm3.fa                            dmel-2L-chromosome-r5.57.fasta.gz\n",
      "dm3.fa.fai                        dmel-2L-r5.57.gff.gz\n",
      "dm3ToDm6.over.chain               dmel-2R-chromosome-r5.57.fasta.gz\n",
      "dm6.fa                            dmel-2R-r5.57.gff.gz\n",
      "dm6.fa.dict                       dmel-3L-chromosome-r5.57.fasta.gz\n",
      "dm6.fa.fai                        dmel-3L-r5.57.gff.gz\n",
      "dm6_introns.bed                   dmel-3R-chromosome-r5.57.fasta.gz\n",
      "dm6_short_introns.bed             dmel-3R-r5.57.gff.gz\n",
      "dmel-2L-chromosome-r5.57.fasta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../../reference/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_001201797.2_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_001201795.2_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_164812.5_intron_4_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_205936.3_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_205935.3_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2                                          3  4  5\n",
       "0  chr2L  8387838  8387882  NM_001201797.2_intron_5_0_chr2L_8387832_f  0  +\n",
       "1  chr2L  8387838  8387882  NM_001201795.2_intron_5_0_chr2L_8387832_f  0  +\n",
       "2  chr2L  8387838  8387882     NM_164812.5_intron_4_0_chr2L_8387832_f  0  +\n",
       "3  chr2L  8387838  8387882     NM_205936.3_intron_5_0_chr2L_8387832_f  0  +\n",
       "4  chr2L  8387838  8387882     NM_205935.3_intron_5_0_chr2L_8387832_f  0  +"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_introns = filter_short_introns_from_bed(\"dm6_introns.bed\", \n",
    "                                              \"dm6_short_introns.bed\", \n",
    "                                              [\"chr2L\", \"chr2R\", \"chr3L\", \"chr3R\"],\n",
    "                                              short_intron_size=86,\n",
    "                                              trailling_size=8)\n",
    "short_introns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the filter based on the BED file intervals (to make sure to only keep `short-intronic` SNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only short-introns SNPs.\n",
    "chr2L_short_introns = filter_snps_by_interval(chr2L_introns, short_introns)\n",
    "chr2R_short_introns = filter_snps_by_interval(chr2R_introns, short_introns)\n",
    "chr3L_short_introns = filter_snps_by_interval(chr3L_introns, short_introns)\n",
    "chr3R_short_introns = filter_snps_by_interval(chr3R_introns, short_introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump these DataFrames as pickle files to avoid re-running it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mPopfly\u001b[m\u001b[m         \u001b[1m\u001b[36mdmel_data_bckp\u001b[m\u001b[m \u001b[1m\u001b[36mmasked\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mdmel_data\u001b[m\u001b[m      dpgp3.txt      \u001b[1m\u001b[36moriginals\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "%cd ../dpgp3\n",
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle chrm short-introns DataFrames\n",
    "# chr2L_short_introns.to_pickle(\"masked/vcfs/tables/chr2L_short_introns_downsampled.pkl\")\n",
    "# chr2R_short_introns.to_pickle(\"masked/vcfs/tables/chr2R_short_introns_downsampled.pkl\")\n",
    "# chr3L_short_introns.to_pickle(\"masked/vcfs/tables/chr3L_short_introns_downsampled.pkl\")\n",
    "# chr3R_short_introns.to_pickle(\"masked/vcfs/tables/chr3R_short_introns_downsampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled chrm short-introns DataFrames\n",
    "# chr2L_short_introns = pd.read_pickle(\"masked/vcfs/tables/chr2L_short_introns_downsampled.pkl\")\n",
    "# chr2R_short_introns = pd.read_pickle(\"masked/vcfs/tables/chr2R_short_introns_downsampled.pkl\")\n",
    "# chr3L_short_introns = pd.read_pickle(\"masked/vcfs/tables/chr3L_short_introns_downsampled.pkl\")\n",
    "# chr3R_short_introns = pd.read_pickle(\"masked/vcfs/tables/chr3R_short_introns_downsampled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many short-introns SNPs were retained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 2728, chr2R = 2384, chr3L = 2073, chr3R = 2967 SNPs!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_short_introns.shape[0], chr2R_short_introns.shape[0], chr3L_short_introns.shape[0], chr3R_short_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(3) Take synonymous and non-synonymous SNPs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset chr2L to retain only SNPs annotated as introns\n",
    "chr2L_exons = chr2L_table[(chr2L_table['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr2L_table['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr2R_exons = chr2R_table[(chr2R_table['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr2R_table['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3L_exons = chr3L_table[(chr3L_table['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr3L_table['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3R_exons = chr3R_table[(chr3R_table['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr3R_table['effect'] == \"SYNONYMOUS_CODING\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle chrm exons DataFrames\n",
    "# chr2L_exons.to_pickle(\"masked/vcfs/tables/chr2L_exons_downsampled.pkl\")\n",
    "# chr2R_exons.to_pickle(\"masked/vcfs/tables/chr2R_exons_downsampled.pkl\")\n",
    "# chr3L_exons.to_pickle(\"masked/vcfs/tables/chr3L_exons_downsampled.pkl\")\n",
    "# chr3R_exons.to_pickle(\"masked/vcfs/tables/chr3R_exons_downsampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled chrm exons DataFrames\n",
    "# chr2L_exons = pd.read_pickle(\"masked/vcfs/tables/chr2L_exons_downsampled.pkl\")\n",
    "# chr2R_exons = pd.read_pickle(\"masked/vcfs/tables/chr2R_exons_downsampled.pkl\")\n",
    "# chr3L_exons = pd.read_pickle(\"masked/vcfs/tables/chr3L_exons_downsampled.pkl\")\n",
    "# chr3R_exons = pd.read_pickle(\"masked/vcfs/tables/chr3R_exons_downsampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 255680, chr2R = 236781, chr3L = 226182, chr3R = 271278 SNPs!'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_exons.shape[0], chr2R_exons.shape[0], chr3L_exons.shape[0], chr3R_exons.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __SNPs counts dictionary__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of SNP counts for each dataFrame containing short-intron SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_short_introns_dict = create_snp_total_counts_dict(chr2L_short_introns)\n",
    "chr2R_short_introns_dict = create_snp_total_counts_dict(chr2R_short_introns)\n",
    "chr3L_short_introns_dict = create_snp_total_counts_dict(chr3L_short_introns)\n",
    "chr3R_short_introns_dict = create_snp_total_counts_dict(chr3R_short_introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get the intron-SFS for each chromosome total count values (this is not downsampled yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chr2L_short_introns_raw_sfs = create_sfs_dict(chr2L_short_introns_dict)\n",
    "chr2R_short_introns_raw_sfs = create_sfs_dict(chr2R_short_introns_dict)\n",
    "chr3L_short_introns_raw_sfs = create_sfs_dict(chr3L_short_introns_dict)\n",
    "chr3R_short_introns_raw_sfs = create_sfs_dict(chr3R_short_introns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_short_introns_sfs = downsample_sfs_in_dict(chr2L_short_introns_raw_sfs, min_number_of_haplotypes, fold=True)\n",
    "chr2R_short_introns_sfs = downsample_sfs_in_dict(chr2R_short_introns_raw_sfs, min_number_of_haplotypes, fold=True)\n",
    "chr3L_short_introns_sfs = downsample_sfs_in_dict(chr3L_short_introns_raw_sfs, min_number_of_haplotypes, fold=True)\n",
    "chr3R_short_introns_sfs = downsample_sfs_in_dict(chr3R_short_introns_raw_sfs, min_number_of_haplotypes, fold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then combined each chromosome short-introns SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_introns_sfs_array = np.array([\n",
    "    chr2L_short_introns_sfs,\n",
    "    chr2R_short_introns_sfs,\n",
    "    chr3L_short_introns_sfs,\n",
    "    chr3R_short_introns_sfs\n",
    "])\n",
    "\n",
    "short_introns_sfs = np.sum(short_introns_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the synonymous SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total counts dictionary for synonymous SNPs\n",
    "chr2L_synonymous_dict = create_snp_total_counts_dict(chr2L_exons[(chr2L_exons['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "chr2R_synonymous_dict = create_snp_total_counts_dict(chr2R_exons[(chr2R_exons['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "chr3L_synonymous_dict = create_snp_total_counts_dict(chr3L_exons[(chr3L_exons['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "chr3R_synonymous_dict = create_snp_total_counts_dict(chr3R_exons[(chr3R_exons['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "\n",
    "# Create synonymous SFS dictionary\n",
    "chr2L_synonymous_raw_sfs = create_sfs_dict(chr2L_synonymous_dict)\n",
    "chr2R_synonymous_raw_sfs = create_sfs_dict(chr2R_synonymous_dict)\n",
    "chr3L_synonymous_raw_sfs = create_sfs_dict(chr3L_synonymous_dict)\n",
    "chr3R_synonymous_raw_sfs = create_sfs_dict(chr3R_synonymous_dict)\n",
    "\n",
    "# Then combined each chromosome synonymous SFS\n",
    "synonymous_sfs_array = np.array([\n",
    "    downsample_sfs_in_dict(chr2L_synonymous_raw_sfs, min_number_of_haplotypes, fold=True),\n",
    "    downsample_sfs_in_dict(chr2R_synonymous_raw_sfs, min_number_of_haplotypes, fold=True),\n",
    "    downsample_sfs_in_dict(chr3L_synonymous_raw_sfs, min_number_of_haplotypes, fold=True),\n",
    "    downsample_sfs_in_dict(chr3R_synonymous_raw_sfs, min_number_of_haplotypes, fold=True)\n",
    "])\n",
    "\n",
    "synonymous_sfs = np.sum(synonymous_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the non-synonymous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total counts dictionary for synonymous SNPs\n",
    "chr2L_nonsynonymous_dict = create_snp_total_counts_dict(chr2L_exons[(chr2L_exons['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "chr2R_nonsynonymous_dict = create_snp_total_counts_dict(chr2R_exons[(chr2R_exons['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "chr3L_nonsynonymous_dict = create_snp_total_counts_dict(chr3L_exons[(chr3L_exons['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "chr3R_nonsynonymous_dict = create_snp_total_counts_dict(chr3R_exons[(chr3R_exons['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "\n",
    "# Create synonymous SFS dictionary\n",
    "chr2L_nonsynonymous_raw_sfs = create_sfs_dict(chr2L_nonsynonymous_dict)\n",
    "chr2R_nonsynonymous_raw_sfs = create_sfs_dict(chr2R_nonsynonymous_dict)\n",
    "chr3L_nonsynonymous_raw_sfs = create_sfs_dict(chr3L_nonsynonymous_dict)\n",
    "chr3R_nonsynonymous_raw_sfs = create_sfs_dict(chr3R_nonsynonymous_dict)\n",
    "\n",
    "# Then combined each chromosome synonymous SFS\n",
    "nonsynonymous_sfs_array = np.array([\n",
    "    downsample_sfs_in_dict(chr2L_nonsynonymous_raw_sfs, min_number_of_haplotypes, fold=True),\n",
    "    downsample_sfs_in_dict(chr2R_nonsynonymous_raw_sfs, min_number_of_haplotypes, fold=True),\n",
    "    downsample_sfs_in_dict(chr3L_nonsynonymous_raw_sfs, min_number_of_haplotypes, fold=True),\n",
    "    downsample_sfs_in_dict(chr3R_nonsynonymous_raw_sfs, min_number_of_haplotypes, fold=True)\n",
    "])\n",
    "\n",
    "nonsynonymous_sfs = np.sum(nonsynonymous_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the three SFSs to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/DGN/dpgp3/masked/vcfs\n",
      "README.md    ZI_Chr3L.vcf chrms        \u001b[1m\u001b[36mremade\u001b[m\u001b[m       \u001b[1m\u001b[36msnpeff\u001b[m\u001b[m\n",
      "ZI_Chr2L.vcf ZI_Chr3R.vcf \u001b[1m\u001b[36mfiltered\u001b[m\u001b[m     \u001b[1m\u001b[36msfss\u001b[m\u001b[m         \u001b[1m\u001b[36mtables\u001b[m\u001b[m\n",
      "ZI_Chr2R.vcf ZI_ChrX.vcf  \u001b[1m\u001b[36mliftover\u001b[m\u001b[m     \u001b[1m\u001b[36msift4g\u001b[m\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd masked/vcfs/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Save the annotated SNP files into snpeff folder\n",
    "sfss_folder=\"sfss\"\n",
    "if [ !  -d \"$sfss_folder\" ]; \n",
    "then\n",
    "    mkdir -p $sfss_folder && ls $sfss_folder\n",
    "else\n",
    "    ls $sfss_folder\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/DGN/dpgp3/masked/vcfs/sfss\n",
      "\u001b[1m\u001b[36mno-pairing\u001b[m\u001b[m \u001b[1m\u001b[36mpaired\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "%cd sfss/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sfs_file = \"no-pairing/ZI_sfs_si_nopairing_downsampled_folded___.txt\"\n",
    "\n",
    "with open(output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Introns, synonymous, and nonsynonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in short_introns_sfs) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in synonymous_sfs) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in nonsynonymous_sfs) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Pair neutral and non-neutral SNPs by mutational context__\n",
    "\n",
    "Now that we had a simple way to get the SFSs, we are going to add some complexities and pair neutral and non-neutral SNPs by their mutational context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mno-pairing\u001b[m\u001b[m \u001b[1m\u001b[36mpaired\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove SNPs that are close to each other, as they might cause ambiguity on the sequence category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Short-introns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True for SNPs far apart and False otherwise, and insert a column on each chromosome DataFrame:\n",
    "# Insert the new column at position 3\n",
    "chr2L_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2L_short_introns[\"pos\"])))\n",
    "chr2R_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2R_short_introns[\"pos\"])))\n",
    "chr3L_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3L_short_introns[\"pos\"])))\n",
    "chr3R_short_introns.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3R_short_introns[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_short_introns = chr2L_short_introns[chr2L_short_introns['pos_to_keep'] == True]\n",
    "chr2R_short_introns = chr2R_short_introns[chr2R_short_introns['pos_to_keep'] == True]\n",
    "chr3L_short_introns = chr3L_short_introns[chr3L_short_introns['pos_to_keep'] == True]\n",
    "chr3R_short_introns = chr3R_short_introns[chr3R_short_introns['pos_to_keep'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 1850, chr2R = 1632, chr3L = 1484, chr3R = 2134 SNPs!'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_short_introns.shape[0], chr2R_short_introns.shape[0], chr3L_short_introns.shape[0], chr3R_short_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Exons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get True for SNPs far apart and False otherwise, and insert a column on each chromosome DataFrame:\n",
    "# Insert the new column at position 3\n",
    "chr2L_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2L_exons[\"pos\"])))\n",
    "chr2R_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr2R_exons[\"pos\"])))\n",
    "chr3L_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3L_exons[\"pos\"])))\n",
    "chr3R_exons.insert(2, \"pos_to_keep\", find_consecutive_positions(list(chr3R_exons[\"pos\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_exons = chr2L_exons[chr2L_exons['pos_to_keep'] == True]\n",
    "chr2R_exons = chr2R_exons[chr2R_exons['pos_to_keep'] == True]\n",
    "chr3L_exons = chr3L_exons[chr3L_exons['pos_to_keep'] == True]\n",
    "chr3R_exons = chr3R_exons[chr3R_exons['pos_to_keep'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 222389, chr2R = 209955, chr3L = 199710, chr3R = 240024 SNPs!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_exons.shape[0], chr2R_exons.shape[0], chr3L_exons.shape[0], chr3R_exons.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the sequence category for each SNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the new column at position 9\n",
    "# For introns:\n",
    "chr2L_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr2L_short_introns))\n",
    "chr2R_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr2R_short_introns))\n",
    "chr3L_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr3L_short_introns))\n",
    "chr3R_short_introns.insert(8, \"sequence_category\", set_snp_sequence_category(chr3R_short_introns))\n",
    "\n",
    "# For exons:\n",
    "chr2L_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr2L_exons))\n",
    "chr2R_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr2R_exons))\n",
    "chr3L_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr3L_exons))\n",
    "chr3R_exons.insert(8, \"sequence_category\", set_snp_sequence_category(chr3R_exons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the sequence category dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['AA/CA', 'AC/AA'], 2: ['CA/CA', 'CC/AA'], 3: ['GA/CA', 'GC/AA'], 4: ['TA/CA', 'TC/AA'], 5: ['AA/CC', 'AC/AC'], 6: ['CA/CC', 'CC/AC'], 7: ['GA/CC', 'GC/AC'], 8: ['TA/CC', 'TC/AC'], 9: ['AA/CG', 'AC/AG'], 10: ['CA/CG', 'CC/AG'], 11: ['GA/CG', 'GC/AG'], 12: ['TA/CG', 'TC/AG'], 13: ['AA/CT', 'AC/AT'], 14: ['CA/CT', 'CC/AT'], 15: ['GA/CT', 'GC/AT'], 16: ['TA/CT', 'TC/AT'], 17: ['AA/GA', 'AG/AA'], 18: ['CA/GA', 'CG/AA'], 19: ['GA/GA', 'GG/AA'], 20: ['TA/GA', 'TG/AA'], 21: ['AA/GC', 'AG/AC'], 22: ['CA/GC', 'CG/AC'], 23: ['GA/GC', 'GG/AC'], 24: ['TA/GC', 'TG/AC'], 25: ['AA/GG', 'AG/AG'], 26: ['CA/GG', 'CG/AG'], 27: ['GA/GG', 'GG/AG'], 28: ['TA/GG', 'TG/AG'], 29: ['AA/GT', 'AG/AT'], 30: ['CA/GT', 'CG/AT'], 31: ['GA/GT', 'GG/AT'], 32: ['TA/GT', 'TG/AT'], 33: ['AA/TA', 'AT/AA'], 34: ['CA/TA', 'CT/AA'], 35: ['GA/TA', 'GT/AA'], 36: ['TA/TA', 'TT/AA'], 37: ['AA/TC', 'AT/AC'], 38: ['CA/TC', 'CT/AC'], 39: ['GA/TC', 'GT/AC'], 40: ['TA/TC', 'TT/AC'], 41: ['AA/TG', 'AT/AG'], 42: ['CA/TG', 'CT/AG'], 43: ['GA/TG', 'GT/AG'], 44: ['TA/TG', 'TT/AG'], 45: ['AA/TT', 'AT/AT'], 46: ['CA/TT', 'CT/AT'], 47: ['GA/TT', 'GT/AT'], 48: ['TA/TT', 'TT/AT'], 49: ['AC/GA', 'AG/CA'], 50: ['CC/GA', 'CG/CA'], 51: ['GC/GA', 'GG/CA'], 52: ['TC/GA', 'TG/CA'], 53: ['AC/GC', 'AG/CC'], 54: ['CC/GC', 'CG/CC'], 55: ['GC/GC', 'GG/CC'], 56: ['TC/GC', 'TG/CC'], 57: ['AC/GG', 'AG/CG'], 58: ['CC/GG', 'CG/CG'], 59: ['GC/GG', 'GG/CG'], 60: ['TC/GG', 'TG/CG'], 61: ['AC/GT', 'AG/CT'], 62: ['CC/GT', 'CG/CT'], 63: ['GC/GT', 'GG/CT'], 64: ['TC/GT', 'TG/CT'], 65: ['AC/TA', 'AT/CA'], 66: ['CC/TA', 'CT/CA'], 67: ['GC/TA', 'GT/CA'], 68: ['TC/TA', 'TT/CA'], 69: ['AC/TC', 'AT/CC'], 70: ['CC/TC', 'CT/CC'], 71: ['GC/TC', 'GT/CC'], 72: ['TC/TC', 'TT/CC'], 73: ['AC/TG', 'AT/CG'], 74: ['CC/TG', 'CT/CG'], 75: ['GC/TG', 'GT/CG'], 76: ['TC/TG', 'TT/CG'], 77: ['AC/TT', 'AT/CT'], 78: ['CC/TT', 'CT/CT'], 79: ['GC/TT', 'GT/CT'], 80: ['TC/TT', 'TT/CT'], 81: ['AG/TA', 'AT/GA'], 82: ['CG/TA', 'CT/GA'], 83: ['GG/TA', 'GT/GA'], 84: ['TG/TA', 'TT/GA'], 85: ['AG/TC', 'AT/GC'], 86: ['CG/TC', 'CT/GC'], 87: ['GG/TC', 'GT/GC'], 88: ['TG/TC', 'TT/GC'], 89: ['AG/TG', 'AT/GG'], 90: ['CG/TG', 'CT/GG'], 91: ['GG/TG', 'GT/GG'], 92: ['TG/TG', 'TT/GG'], 93: ['AG/TT', 'AT/GT'], 94: ['CG/TT', 'CT/GT'], 95: ['GG/TT', 'GT/GT'], 96: ['TG/TT', 'TT/GT']}\n"
     ]
    }
   ],
   "source": [
    "# First create a object for the sequence categories dictionary\n",
    "sequence_categories_dict = create_sequence_categories_dict()\n",
    "print(sequence_categories_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create three dictionaries for each chromosome\n",
    "# For introns\n",
    "chr2L_short_introns_seqclasses = create_snp_dict_wrapper(chr2L_short_introns, sequence_categories_dict, \"introns\")\n",
    "chr2R_short_introns_seqclasses = create_snp_dict_wrapper(chr2R_short_introns, sequence_categories_dict, \"introns\")\n",
    "chr3L_short_introns_seqclasses = create_snp_dict_wrapper(chr3L_short_introns, sequence_categories_dict, \"introns\")\n",
    "chr3R_short_introns_seqclasses = create_snp_dict_wrapper(chr3R_short_introns, sequence_categories_dict, \"introns\")\n",
    "\n",
    "# For exons\n",
    "chr2L_nonsyns_seqclasses, chr2L_syns_seqclasses = create_snp_dict_wrapper(chr2L_exons, sequence_categories_dict, \"exons\")\n",
    "chr2R_nonsyns_seqclasses, chr2R_syns_seqclasses = create_snp_dict_wrapper(chr2R_exons, sequence_categories_dict, \"exons\")\n",
    "chr3L_nonsyns_seqclasses, chr3L_syns_seqclasses = create_snp_dict_wrapper(chr3L_exons, sequence_categories_dict, \"exons\")\n",
    "chr3R_nonsyns_seqclasses, chr3R_syns_seqclasses = create_snp_dict_wrapper(chr3R_exons, sequence_categories_dict, \"exons\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find mutational context pairs and get the SFSs\n",
    "Now, find the pairs and obtain the SFSs for each member of the pair. These are the valid pairs we are looking to have:\n",
    "- `short-intron SNP` and `non-synonymous SNPs`;\n",
    "- `short-intron SNP` and `synonymous SNPs`;\n",
    "- `synonymous SNP` and `non-synonymous SNPs` (maybe?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `short-intron SNP` and `non-synonymous SNPs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs of SNPs that are closest to each other\n",
    "chr2L_si_nonsyn_pairs_si, chr2L_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2L_short_introns_seqclasses, chr2L_nonsyns_seqclasses)\n",
    "chr2R_si_nonsyn_pairs_si, chr2R_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2R_short_introns_seqclasses, chr2R_nonsyns_seqclasses)\n",
    "chr3L_si_nonsyn_pairs_si, chr3L_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3L_short_introns_seqclasses, chr3L_nonsyns_seqclasses)\n",
    "chr3R_si_nonsyn_pairs_si, chr3R_si_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3R_short_introns_seqclasses, chr3R_nonsyns_seqclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n"
     ]
    }
   ],
   "source": [
    "# Get the SFS for the short introns SNPs\n",
    "# Remember: the data is now sampled, so the max_sample_size means the lower bound set to 160.\n",
    "# Use the imputed argument, knowing that the data was sampled.\n",
    "short_introns_paired_nonsyn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_nonsyn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_nonsyn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_nonsyn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_nonsyn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "short_introns_paired_nonsyn_seqclasses_sfs_folded = np.sum(short_introns_paired_nonsyn_sfs_seqclasses_array, 0).tolist()\n",
    "\n",
    "# Get the SFS for the nonsynonymous SNPs\n",
    "nonsynonymous_paired_si_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "nonsynonymous_paired_si_seqclasses_sfs_folded = np.sum(nonsynonymous_paired_si_sfs_seqclasses_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pairs to a file\n",
    "si_nonsyn_pair_output_sfs_file = \"paired/ZI_sfs_si_paired_with_nonsynonymous_downsampled_folded.txt\"\n",
    "\n",
    "with open(si_nonsyn_pair_output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Introns and nonsynonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in short_introns_paired_nonsyn_seqclasses_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in nonsynonymous_paired_si_seqclasses_sfs_folded) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `short-intron SNP` and `synonymous SNPs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs of SNPs that are closest to each other\n",
    "chr2L_si_syn_pairs_si, chr2L_si_syn_pairs_syn = find_closest_snp_pairs(chr2L_short_introns_seqclasses, chr2L_syns_seqclasses)\n",
    "chr2R_si_syn_pairs_si, chr2R_si_syn_pairs_syn = find_closest_snp_pairs(chr2R_short_introns_seqclasses, chr2R_syns_seqclasses)\n",
    "chr3L_si_syn_pairs_si, chr3L_si_syn_pairs_syn = find_closest_snp_pairs(chr3L_short_introns_seqclasses, chr3L_syns_seqclasses)\n",
    "chr3R_si_syn_pairs_si, chr3R_si_syn_pairs_syn = find_closest_snp_pairs(chr3R_short_introns_seqclasses, chr3R_syns_seqclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n"
     ]
    }
   ],
   "source": [
    "# Get the SFS for the short introns SNPs\n",
    "short_introns_paired_syn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_syn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_syn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_syn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_syn_pairs_si, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "short_introns_paired_syn_seqclasses_sfs_folded = np.sum(short_introns_paired_syn_sfs_seqclasses_array, 0).tolist()\n",
    "\n",
    "# Get the SFS for the synonymous SNPs\n",
    "synonymous_paired_si_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_si_syn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_si_syn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_si_syn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_si_syn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "synonymous_paired_si_seqclasses_sfs_folded = np.sum(synonymous_paired_si_sfs_seqclasses_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pairs to a file\n",
    "si_syn_pair_output_sfs_file = \"paired/ZI_sfs_si_paired_with_synonymous_downsampled_folded_.txt\"\n",
    "\n",
    "with open(si_syn_pair_output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Introns and synonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in short_introns_paired_syn_seqclasses_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in synonymous_paired_si_seqclasses_sfs_folded) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `synonymous SNP` and `non-synonymous SNPs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pairs of SNPs that are closest to each other\n",
    "chr2L_syn_nonsyn_pairs_syn, chr2L_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2L_syns_seqclasses, chr2L_nonsyns_seqclasses)\n",
    "chr2R_syn_nonsyn_pairs_syn, chr2R_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr2R_syns_seqclasses, chr2R_nonsyns_seqclasses)\n",
    "chr3L_syn_nonsyn_pairs_syn, chr3L_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3L_syns_seqclasses, chr3L_nonsyns_seqclasses)\n",
    "chr3R_syn_nonsyn_pairs_syn, chr3R_syn_nonsyn_pairs_nonsyn = find_closest_snp_pairs(chr3R_syns_seqclasses, chr3R_nonsyns_seqclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n",
      "Working with downsampled data...\n"
     ]
    }
   ],
   "source": [
    "# Get the SFS for the synonymous SNPs\n",
    "synonymous_paired_nonsyn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_syn_nonsyn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_syn_nonsyn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_syn_nonsyn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_syn_nonsyn_pairs_syn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "synonymous_paired_nonsyn_seqclasses_sfs_folded = np.sum(synonymous_paired_nonsyn_sfs_seqclasses_array, 0).tolist()\n",
    "\n",
    "# Get the SFS for the nonsynonymous SNPs\n",
    "nonsynonymous_paired_syn_sfs_seqclasses_array = np.array([\n",
    "    create_unfolded_sfs_from_snp_dict(chr2L_syn_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr2R_syn_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3L_syn_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True),\n",
    "    create_unfolded_sfs_from_snp_dict(chr3R_syn_nonsyn_pairs_nonsyn, \"downsampled\", max_sample_size=197, min_sample_size=min_number_of_haplotypes, folded=True)\n",
    "])\n",
    "\n",
    "nonsynonymous_paired_syn_seqclasses_sfs_folded = np.sum(nonsynonymous_paired_syn_sfs_seqclasses_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pairs to a file\n",
    "syn_nonsyn_pair_output_sfs_file = \"paired/ZI_sfs_synonymous_paired_with_nonsynnonymous_downsampled_folded.txt\"\n",
    "\n",
    "with open(syn_nonsyn_pair_output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Synonymous and nonsynonymous SFS of \" + str(min_number_of_haplotypes) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in synonymous_paired_nonsyn_seqclasses_sfs_folded) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in nonsynonymous_paired_syn_seqclasses_sfs_folded) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
