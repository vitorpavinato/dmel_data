{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Pipeline 2: SNP processing__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Requirements__\n",
    "- a python environment (installed with conda for example);\n",
    "- .TSV files from the obtained with pipeline 1;\n",
    "- python `subprocess`;\n",
    "- python `Numpy`;\n",
    "- python `Pandas`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from snp_utils import filter_short_introns_from_bed, filter_snps_by_interval, create_snp_total_counts_dict\n",
    "from sfs_utils import create_sfs_dict, downsample_sfs_in_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Import the tables into Pandas__\n",
    "\n",
    "We are going to use pandas to import the SNP table. Pandas is a great (if used with cauting) Python package built on Numpy which allows easy dataFrame manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/Documents/Repositories/dmel_data/create_sfss/examples\n",
      "chr2L_example_ann_table.tsv chr3R_example_ann_table.tsv\n",
      "chr2R_example_ann_table.tsv \u001b[1m\u001b[36mresults\u001b[m\u001b[m\n",
      "chr3L_example_ann_table.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd examples/\n",
    "!ls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the `.tsv` file for each chromosome (except for the __chrom4__ and __chromX__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload files with pd.read_table()\n",
    "chr2L_table = pd.read_table(\"chr2L_example_ann_table.tsv\")\n",
    "chr2R_table = pd.read_table(\"chr2R_example_ann_table.tsv\")\n",
    "chr3L_table = pd.read_table(\"chr3L_example_ann_table.tsv\")\n",
    "chr3R_table = pd.read_table(\"chr3R_example_ann_table.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of SNPs in each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 1000, chr2R = 1000, chr3L = 1000, chr3R = 1000 SNPs!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_table.shape[0], chr2R_table.shape[0], chr3L_table.shape[0], chr3R_table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>id</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>refcount</th>\n",
       "      <th>altcount</th>\n",
       "      <th>refflank</th>\n",
       "      <th>altflank</th>\n",
       "      <th>refcodon</th>\n",
       "      <th>...</th>\n",
       "      <th>snpeff_trnscid</th>\n",
       "      <th>sift_trnscid</th>\n",
       "      <th>sift_geneid</th>\n",
       "      <th>sift_genename</th>\n",
       "      <th>sift_region</th>\n",
       "      <th>sift_vartype</th>\n",
       "      <th>sifts_core</th>\n",
       "      <th>sift_median</th>\n",
       "      <th>sift_pred</th>\n",
       "      <th>deleteriousness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5090</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>CATTTTCTC</td>\n",
       "      <td>CATTCTCTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5095</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>104</td>\n",
       "      <td>TCTCTCCCA</td>\n",
       "      <td>TCTCACCCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5110</td>\n",
       "      <td>.</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>AGGGTGAAA</td>\n",
       "      <td>AGGGAGAAA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5118</td>\n",
       "      <td>.</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>ATATGATCG</td>\n",
       "      <td>ATATTATCG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>5140</td>\n",
       "      <td>.</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>158</td>\n",
       "      <td>2</td>\n",
       "      <td>AGTGCCAAC</td>\n",
       "      <td>AGTGTCAAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>FBtr0475186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom   pos id ref alt  refcount  altcount   refflank   altflank refcodon  \\\n",
       "0  chr2L  5090  .   T   C       103         3  CATTTTCTC  CATTCTCTC      NaN   \n",
       "1  chr2L  5095  .   T   A        16       104  TCTCTCCCA  TCTCACCCA      NaN   \n",
       "2  chr2L  5110  .   T   A       130         2  AGGGTGAAA  AGGGAGAAA      NaN   \n",
       "3  chr2L  5118  .   G   T       147         1  ATATGATCG  ATATTATCG      NaN   \n",
       "4  chr2L  5140  .   C   T       158         2  AGTGCCAAC  AGTGTCAAC      NaN   \n",
       "\n",
       "   ... snpeff_trnscid sift_trnscid sift_geneid sift_genename sift_region  \\\n",
       "0  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "1  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "2  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "3  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "4  ...    FBtr0475186          NaN         NaN           NaN         NaN   \n",
       "\n",
       "  sift_vartype sifts_core sift_median sift_pred deleteriousness  \n",
       "0          NaN        NaN         NaN       NaN             NaN  \n",
       "1          NaN        NaN         NaN       NaN             NaN  \n",
       "2          NaN        NaN         NaN       NaN             NaN  \n",
       "3          NaN        NaN         NaN       NaN             NaN  \n",
       "4          NaN        NaN         NaN       NaN             NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at chr2R\n",
    "chr2L_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Subset SNPs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Subset each chromosome to retain only:__\n",
    "- `SNPs in short-introns`;\n",
    "- `Synonymous SNPs`;\n",
    "- `Non-synonymous SNPs`;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(1) Subset to retain only SNPs annotated as introns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chr2L_introns = chr2L_table[(chr2L_table['effect'] == \"INTRON\")]\n",
    "chr2L_introns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the other chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset chr2L to retain only SNPs annotated as introns\n",
    "chr2R_introns = chr2R_table[(chr2R_table['effect'] == \"INTRON\")]\n",
    "chr3L_introns = chr3L_table[(chr3L_table['effect'] == \"INTRON\")]\n",
    "chr3R_introns = chr3R_table[(chr3R_table['effect'] == \"INTRON\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 146, chr2R = 146, chr3L = 146, chr3R = 146 SNPs!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_introns.shape[0], chr2R_introns.shape[0], chr3L_introns.shape[0], chr3R_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(2)Keep only short intronic SNPs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each chromosome, retain only SNPs in `short introns`. To do that, you need to identify the short-intros in Dm6 genome and head/tail the sequence to remove head and trailing 8bp from each short-intron. These extremes migh be under selection constraints. Download the intron regions as `.BED` file from [here](https://genome.ucsc.edu/cgi-bin/hgTables). Select *D. melanogaster* assembly known as *Dm6* (Aug. 2014, BDGP Release 6 + ISO 1 MT/dm6). Define the region of interest as `genome`, select the output format as `BED` and name it. In the next page, select only `Introns plus 0`, then hit `Get BED`. Now you are ready to go. The next step is to create a Pandas DataFrame with short introns intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/Documents/Repositories/dmel_data/create_sfss\n",
      "README.md\n",
      "__init__.py\n",
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mexamples\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mintervals\u001b[m\u001b[m\n",
      "mutational_context_utils.py\n",
      "pipeline_to_process_snps.ipynb\n",
      "pipeline_to_process_snps_with_imputation.ipynb\n",
      "sfs_utils.py\n",
      "snp_utils.py\n",
      "test_create_sfs_dict.py\n",
      "test_create_snp_total_counts_dict.py\n",
      "test_create_unfolded_sfs_from_df.py\n",
      "test_downsample_sfs.py\n",
      "test_filter_snps_by_interval.py\n",
      "test_fold_sfs.py\n",
      "test_impute_missing_haplotypes.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_001201797.2_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_001201795.2_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_164812.5_intron_4_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_205936.3_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>8387838</td>\n",
       "      <td>8387882</td>\n",
       "      <td>NM_205935.3_intron_5_0_chr2L_8387832_f</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2                                          3  4  5\n",
       "0  chr2L  8387838  8387882  NM_001201797.2_intron_5_0_chr2L_8387832_f  0  +\n",
       "1  chr2L  8387838  8387882  NM_001201795.2_intron_5_0_chr2L_8387832_f  0  +\n",
       "2  chr2L  8387838  8387882     NM_164812.5_intron_4_0_chr2L_8387832_f  0  +\n",
       "3  chr2L  8387838  8387882     NM_205936.3_intron_5_0_chr2L_8387832_f  0  +\n",
       "4  chr2L  8387838  8387882     NM_205935.3_intron_5_0_chr2L_8387832_f  0  +"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_introns = filter_short_introns_from_bed(\"intervals/dm6_introns.bed\", \n",
    "                                              \"intervals/dm6_short_introns.bed\", \n",
    "                                              [\"chr2L\", \"chr2R\", \"chr3L\", \"chr3R\"],\n",
    "                                              short_intron_size=86,\n",
    "                                              trailling_size=8)\n",
    "short_introns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the filter based on the BED file intervals (to make sure to only keep `short-intronic` SNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only SNPs in exons and in short-introns\n",
    "chr2L_short_introns = filter_snps_by_interval(chr2L_introns, short_introns)\n",
    "chr2R_short_introns = filter_snps_by_interval(chr2R_introns, short_introns)\n",
    "chr3L_short_introns = filter_snps_by_interval(chr3L_introns, short_introns)\n",
    "chr3R_short_introns = filter_snps_by_interval(chr3R_introns, short_introns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many short-introns SNPs were retained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 0, chr2R = 0, chr3L = 0, chr3R = 0 SNPs!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_short_introns.shape[0], chr2R_short_introns.shape[0], chr3L_short_introns.shape[0], chr3R_short_introns.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(3) Take synonymous and non-synonymous SNPs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 29)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr2L_exons = chr2L_table[(chr2L_table['effect'] == \"NON_SYNONYMOUS_CODING\") |\n",
    "                          (chr2L_table['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr2L_exons.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same on the other chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset chr2L to retain only SNPs annotated as introns\n",
    "chr2R_exons = chr2R_table[(chr2L_table['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr2L_table['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3L_exons = chr3L_table[(chr2L_table['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr2L_table['effect'] == \"SYNONYMOUS_CODING\")]\n",
    "chr3R_exons = chr3R_table[(chr2L_table['effect'] == \"NON_SYNONYMOUS_CODING\") | (chr2L_table['effect'] == \"SYNONYMOUS_CODING\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 242, chr2R = 242, chr3L = 242, chr3R = 242 SNPs!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, chr3R = {} SNPs!\".format(chr2L_exons.shape[0], chr2R_exons.shape[0], chr3L_exons.shape[0], chr3R_exons.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Subset each chromosome to retain only SNPs with the total count (`refcount` + `altcount`) higher than a threshould__\n",
    "\n",
    "Let's start with SNPs with more than 160 haplotypes ( `total count` > 160).\n",
    "But before doing that, lets combine introns and exons SNPs in one dataset for each chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only intronic SNPs wiht total counts > 160 haplotypes (for the example use all introns)\n",
    "chr2L_introns_mincounts = chr2L_introns[chr2L_introns['refcount'] + chr2L_introns['altcount'] >= total_counts]\n",
    "chr2R_introns_mincounts = chr2R_introns[chr2R_introns['refcount'] + chr2R_introns['altcount'] >= total_counts]\n",
    "chr3L_introns_mincounts = chr3L_introns[chr3L_introns['refcount'] + chr3L_introns['altcount'] >= total_counts]\n",
    "chr3R_introns_mincounts = chr3R_introns[chr3R_introns['refcount'] + chr3R_introns['altcount'] >= total_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 144, chr2R = 144, chr3L = 144, and chr3R = 144  SNPs!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, and chr3R = {}  SNPs!\".format(chr2L_introns_mincounts.shape[0], chr2R_introns_mincounts.shape[0], chr3L_introns_mincounts.shape[0], chr3R_introns_mincounts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only exonic SNPs wiht total counts > 160 haplotypes\n",
    "chr2L_exons_mincounts = chr2L_exons[chr2L_exons['refcount'] + chr2L_exons['altcount'] >= total_counts]\n",
    "chr2R_exons_mincounts = chr2R_exons[chr2R_exons['refcount'] + chr2R_exons['altcount'] >= total_counts]\n",
    "chr3L_exons_mincounts = chr3L_exons[chr3L_exons['refcount'] + chr3L_exons['altcount'] >= total_counts]\n",
    "chr3R_exons_mincounts = chr3R_exons[chr3R_exons['refcount'] + chr3R_exons['altcount'] >= total_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chr2L = 242, chr2R = 242, chr3L = 242, and chr3R = 242  SNPs!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the number of SNPs with .shape\n",
    "\"chr2L = {}, chr2R = {}, chr3L = {}, and chr3R = {}  SNPs!\".format(chr2L_exons_mincounts.shape[0], chr2R_exons_mincounts.shape[0], chr3L_exons_mincounts.shape[0], chr3R_exons_mincounts.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __SNPs counts dictionary__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary of SNP counts for each dataFrame containing short-intron SNPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_introns_dict = create_snp_total_counts_dict(chr2L_introns_mincounts)\n",
    "chr2R_introns_dict = create_snp_total_counts_dict(chr2R_introns_mincounts)\n",
    "chr3L_introns_dict = create_snp_total_counts_dict(chr3L_introns_mincounts)\n",
    "chr3R_introns_dict = create_snp_total_counts_dict(chr3R_introns_mincounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get the intron-SFS for each chromosome total count values (this is not downsampled yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chr2L_introns_raw_sfs = create_sfs_dict(chr2L_introns_dict)\n",
    "chr2R_introns_raw_sfs = create_sfs_dict(chr2R_introns_dict)\n",
    "chr3L_introns_raw_sfs = create_sfs_dict(chr3L_introns_dict)\n",
    "chr3R_introns_raw_sfs = create_sfs_dict(chr3R_introns_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr2L_introns_sfs = downsample_sfs_in_dict(chr2L_introns_raw_sfs, total_counts, fold=True)\n",
    "chr2R_introns_sfs = downsample_sfs_in_dict(chr2R_introns_raw_sfs, total_counts, fold=True)\n",
    "chr3L_introns_sfs = downsample_sfs_in_dict(chr3L_introns_raw_sfs, total_counts, fold=True)\n",
    "chr3R_introns_sfs = downsample_sfs_in_dict(chr3R_introns_raw_sfs, total_counts, fold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then combined each chromosome short-introns SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_sfs_array = np.array([\n",
    "    chr2L_introns_sfs,\n",
    "    chr2R_introns_sfs,\n",
    "    chr3L_introns_sfs,\n",
    "    chr3R_introns_sfs\n",
    "])\n",
    "\n",
    "introns_sfs = np.sum(introns_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the synonymous SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total counts dictionary for synonymous SNPs\n",
    "chr2L_synonymous_dict = create_snp_total_counts_dict(chr2L_exons_mincounts[(chr2L_exons_mincounts['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "chr2R_synonymous_dict = create_snp_total_counts_dict(chr2R_exons_mincounts[(chr2R_exons_mincounts['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "chr3L_synonymous_dict = create_snp_total_counts_dict(chr3L_exons_mincounts[(chr3L_exons_mincounts['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "chr3R_synonymous_dict = create_snp_total_counts_dict(chr3R_exons_mincounts[(chr3R_exons_mincounts['effect'] == \"SYNONYMOUS_CODING\")])\n",
    "\n",
    "# Create synonymous SFS dictionary\n",
    "chr2L_synonymous_raw_sfs = create_sfs_dict(chr2L_synonymous_dict)\n",
    "chr2R_synonymous_raw_sfs = create_sfs_dict(chr2R_synonymous_dict)\n",
    "chr3L_synonymous_raw_sfs = create_sfs_dict(chr3L_synonymous_dict)\n",
    "chr3R_synonymous_raw_sfs = create_sfs_dict(chr3R_synonymous_dict)\n",
    "\n",
    "# Then combined each chromosome synonymous SFS\n",
    "synonymous_sfs_array = np.array([\n",
    "    downsample_sfs_in_dict(chr2L_synonymous_raw_sfs, total_counts, fold=True),\n",
    "    downsample_sfs_in_dict(chr2R_synonymous_raw_sfs, total_counts, fold=True),\n",
    "    downsample_sfs_in_dict(chr3L_synonymous_raw_sfs, total_counts, fold=True),\n",
    "    downsample_sfs_in_dict(chr3R_synonymous_raw_sfs, total_counts, fold=True)\n",
    "])\n",
    "\n",
    "synonymous_sfs = np.sum(synonymous_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the non-synonymous one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total counts dictionary for synonymous SNPs\n",
    "chr2L_nonsynonymous_dict = create_snp_total_counts_dict(chr2L_exons_mincounts[(chr2L_exons_mincounts['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "chr2R_nonsynonymous_dict = create_snp_total_counts_dict(chr2R_exons_mincounts[(chr2R_exons_mincounts['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "chr3L_nonsynonymous_dict = create_snp_total_counts_dict(chr3L_exons_mincounts[(chr3L_exons_mincounts['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "chr3R_nonsynonymous_dict = create_snp_total_counts_dict(chr3R_exons_mincounts[(chr3R_exons_mincounts['effect'] == \"NON_SYNONYMOUS_CODING\")])\n",
    "\n",
    "# Create synonymous SFS dictionary\n",
    "chr2L_nonsynonymous_raw_sfs = create_sfs_dict(chr2L_nonsynonymous_dict)\n",
    "chr2R_nonsynonymous_raw_sfs = create_sfs_dict(chr2R_nonsynonymous_dict)\n",
    "chr3L_nonsynonymous_raw_sfs = create_sfs_dict(chr3L_nonsynonymous_dict)\n",
    "chr3R_nonsynonymous_raw_sfs = create_sfs_dict(chr3R_nonsynonymous_dict)\n",
    "\n",
    "# Then combined each chromosome synonymous SFS\n",
    "nonsynonymous_sfs_array = np.array([\n",
    "    downsample_sfs_in_dict(chr2L_nonsynonymous_raw_sfs, total_counts, fold=True),\n",
    "    downsample_sfs_in_dict(chr2R_nonsynonymous_raw_sfs, total_counts, fold=True),\n",
    "    downsample_sfs_in_dict(chr3L_nonsynonymous_raw_sfs, total_counts, fold=True),\n",
    "    downsample_sfs_in_dict(chr3R_nonsynonymous_raw_sfs, total_counts, fold=True)\n",
    "])\n",
    "\n",
    "nonsynonymous_sfs = np.sum(nonsynonymous_sfs_array, 0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the three SFSs to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tur92196/Documents/Repositories/dmel_data/create_sfss/examples/results\n",
      "example_imputed_folded_sfs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/dmelnexus/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd examples/results/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sfs_file = \"example_downsampled_folded_sfs.txt\"\n",
    "\n",
    "with open(output_sfs_file, \"w\") as of:\n",
    "    of.write(\"Introns, synonymous, and nonsynonymous SFS of \" + str(total_counts) + \" samples\" + \"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in introns_sfs) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in synonymous_sfs) + \"\\n\")\n",
    "    of.write(\"\\n\")\n",
    "    of.write(\"\\t\".join(str(item) for item in nonsynonymous_sfs) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
